arrange(body_mass_g)
penguins%>% arrange(bill_length_mm)
---
install.packages('Tmisc')
library(Tmisc)
data(quartet)
View(quartet)
quartet %>%
group_by(set) %>%
summarize(mean(x),sd(x),meaan(y),sd(y),cor(x,y))
quartet %>%
group_by(set) %>%
summarize(mean(x),sd(x),mean(y),sd(y),cor(x,y))
ggplot(quartet,aes(x,y))
ggplot(quartet,aes(x,y))+geom_point()+geom_smooth(method = 1m,se=FALSE)+facet_wrap(-set_here())
ggplot(quartet,aes(x,y)) + geom_point() + geom_smooth(method=1m,se=FALSE) + facet_wrap(set_here())
ggplot(quartet,aes(x,y)) + geom_point() + geom_smooth(method=1m,se=FALSE) + facet_wrap(˜set_here())
ggplot(quartet,aes(x,y)) + geom_point() + geom_smooth(method=1m,se=FALSE) + facet_wrap(-set_here())
ggplot(quartet,aes(x,y)) + geom_point() + geom_smooth(method=1m,se=FALSE) + facet_wrap(-set())
ggplot(quartet,aes(x,y)) + geom_point() + geom_smooth(method=1m,se=FALSE)) + facet_wrap(-set())
install.packages("datasauRus")
library(datasauRus)
ggplot(datasaurus_dozen,aes(x=x,y=y,colour=dataset))+geom_point()+theme_void()+theme(legend.position = "none")+facet_wrap(dataset)
ggplot(datasaurus_dozen,aes(x=x,y=y,colour=dataset))+geom_point()+theme_void()+theme(legend.position = "none")+facet_wrap(dataset,ncol=3)
ggplot(datasaurus_dozen,aes(x=x,y=y,colour=dataset))+geom_point()+theme_void()+theme(legend.position = "none")+facet_wrap(-dataset,ncol=3)
ggplot(datasaurus_dozen,aes(x=x,y=y,colour=dataset))+geom_point()+theme_void()+theme(legend.position = "none")+facet_wrap(˜dataset,ncol=3)
ggplot(datasaurus_dozen,aes(x=x,y=y,colour=dataset))+geom_point()+theme_void()+theme(legend.position = "none")+facet_wrap(~dataset,ncol=3)
ggplot(quartet,aes(x,y)) + geom_point() + geom_smooth(method=1m,se=FALSE) + facet_wrap(~set())
ggplot(quartet,aes(x,y)) + geom_point() + geom_smooth(method=1m,se=FALSE) + facet_wrap(~set(),ncol=3)
ggplot(datasaurus_dozen,aes(x=x,y=y,colour=dataset))+geom_point()+theme_void()+theme(legend.position = "none")+facet_wrap(~dataset,ncol=3)
install.packages("SimDesign")
library(SimDesign)
actual_temp<-c(68.3,70,72.4,71,67,70)
predicted_temp<-c(67.9,69,71.5,70,67,69)
bias(predicted_temp,actual_temp)
str(penguins)
head(penguins)
arrange(bill_lenght_mm, penguins)
str(penguins)
arrange(bill_lenght_mm)
arrange(bill_length_mm)
arrange(bill_length_mm)
arrange(bill_depth_mm)
arrange(bill_lenght_mm)
arrange(bill_length_mm, penguins)
arrange(penguins)
arrange(penguins, bill_length_mm)
penguins %>% group_by(island) %>% drop_na() %>% summarize(max_bill_length_mm=max(bill_length_mm))
penguins %>% group_by(species) %>% drop_na() %>% summarize(max_bill_length_mm=max(bill_length_mm))
penguins %>% group_by(species) %>% drop_na() %>% summarize(max_bill_length_mm=max(bill_deph_mm))
str(penguins)
penguins %>% group_by(species) %>% drop_na() %>% summarize(max_bill_length_mm=max( bill_depth_mm))
penguins %>% group_by(species) %>% drop_na() %>% summarize(bill_depth_mm=max( bill_depth_mm))
penguins %>% drop_na() %>% group_by(species) %>% summarize(bill_depth_mm=max( bill_depth_mm))
penguins %>% drop_na() %>% group_by(species) %>% summarize(bill_depth_mm=min( bill_depth_mm))
unite (employee,'name', first_name,last_name,sep=' ')
install.packages("ggplot2")
install.packages("palmerpenguins")
library(ggplot2)
library(palmerpenguins)
data(penguins)
View(penguins)
View(penguins)
ggplot(data = penguins) +geom_point(mapping = aes(x = flipper_length_mm, y = body_mass_g))
ggplot(data = penguins) +geom_barr(mapping = aes(x = flipper_length_mm, y = body_mass_g))
str(penguins)
ggplot(data = penguins) +geom_bar(mapping = aes(x = sex, y = body_mass_g))
ggplot(data = penguins) +geom_bar(mapping = aes(x = year, y = body_mass_g))
rlang::last_error()
ggplot(data = penguins) +geom_point(mapping = aes(x = flipper_length_mm, y = body_mass_g))
ggplot(data = penguins) +geom_point(mapping = aes(x = year, y = body_mass_g))
ggplot(data = penguins) +geom_point(mapping = aes(x = sex, y = body_mass_g))
ggplot(data = penguins) +geom_point(mapping = aes(x = flipper_length_mm, y = body_mass_g, color=species))
ggplot(data = penguins) +geom_point(mapping = aes(x = flipper_length_mm, y = body_mass_g, shape=species))
ggplot(data = penguins) +geom_point(mapping = aes(x = flipper_length_mm, y = body_mass_g, shape=species, color=species))
ggplot(data = penguins) +geom_point(mapping = aes(x = flipper_length_mm, y = body_mass_g, shape=species, color=species,size=species))
ggplot(data = penguins) +geom_point(mapping = aes(x = flipper_length_mm, y = body_mass_g, shape=species, alpha=species,size=species))
ggplot(data = penguins) +geom_point(mapping = aes(x = flipper_length_mm, y = body_mass_g, shape=species, alpha=species))
ggplot(data = penguins) +geom_point(mapping = aes(x = flipper_length_mm, y = body_mass_g))+color="red"
ggplot(data = penguins) +geom_point(mapping = aes(x = flipper_length_mm, y = body_mass_g),color="red")
bars_df %>% read_csv("flavors_of_cacao.csv")
read_csv("flavors_of_cacao.csv") + bars_df
bars_df <- read_csv("flavors_of_cacao.csv")
bars_df + read_csv("flavors_of_cacao.csv")
glimpse(vitae)
install.packages("remotes")
remotes::install_github("davidsjoberg/ggsankey")
library(ggsankey)
library(ggplot2)
library(dplyr) # Necesario
ggplot(df, aes(x = x,
next_x = next_x,
node = node,
next_node = next_node,
fill = factor(node),
label = node)) +
geom_sankey(flow.alpha = 0.5, node.color = 1) +
geom_sankey_label(size = 3.5, color = 1, fill = "white") +
scale_fill_viridis_d() +
theme_sankey(base_size = 16) +
theme(legend.position = "none")
ggplot(p, aes(x = x,
next_x = next_x,
node = node,
next_node = next_node,
fill = factor(node),
label = node)) +
geom_sankey(flow.alpha = 0.5, node.color = 1) +
geom_sankey_label(size = 3.5, color = 1, fill = "white") +
scale_fill_viridis_d() +
theme_sankey(base_size = 16) +
theme(legend.position = "none")
help.start
clean
clean ??
? clean
ls
clean
clean()
clc()
# dimensión del data frame
dim(netflix)
net.2015 <- netflix[netflix$release_year > 2015, ]
# escritura del archivo
write.csv(net.2015, "res.netflix.csv")
# escritura del archivo
write.csv(net.2015, "d:/res.netflix.csv")
# escritura del archivo
write.csv(net.2015, "D:/BajadoEnD/res.netflix.csv")
net.2015 <- netflix[netflix$release_year > 2015, ]
# titulos que se estrenaron despues del 2015
net.2015 <- netflix[netflix$release_year > 2015, ]
netflix
head(netflix)
# dimensión del data frame
head(netflix,10)
dim(netflix)
# Reto 1
# dimensión del data frame
dim(netflix)
# escritura del archivo
write.csv(net.2015, "res.netflix.csv")
set.seed(10)
x <- w <- rnorm(200)
x
w
for(t in 2:200) x[t] <- 0.8 * x[t-1] + w[t]
plot(x, type = "l", xlab = "", ylab = "")
title(main = "Proceso AR(1) simulado",
xlab = "Tiempo",
ylab = expression(x[t]),
sub = expression(x[t]==0.8*x[t-1]+w[t]))
acf(x, main = "")
title(main = "Correlograma del proceso AR(1) simulado",
sub = expression(x[t]==0.8*x[t-1]+w[t]))
pacf(x, main = "")
title(main = "Correlograma Parcial del proceso AR(1) simulado",
sub = expression(x[t]==0.8*x[t-1]+w[t]))
class(x)
class(w)
class(t)
acf(x, main = "")
title(main = "Correlograma del proceso AR(1) simulado",
sub = expression(x[t]==0.8*x[t-1]+w[t]))
ar(x, method = "mle")
set.seed(10)
x <- w <- rnorm(200)
for(t in 2:200) x[t] <- 0.8 * x[t-1] + w[t]
plot(x, type = "l", xlab = "", ylab = "")
title(main = "Proceso AR(1) simulado",
xlab = "Tiempo",
ylab = expression(x[t]),
sub = expression(x[t]==0.8*x[t-1]+w[t]))
acf(x, main = "")
title(main = "Correlograma del proceso AR(1) simulado",
sub = expression(x[t]==0.8*x[t-1]+w[t]))
pacf(x, main = "")
title(main = "Correlograma Parcial del proceso AR(1) simulado",
sub = expression(x[t]==0.8*x[t-1]+w[t]))
ar(x, method = "mle")
ar(x, method = "burg")
con un término autorregresivo y uno de media móvil, junto con sus coeficientes asociados"
y <- arima.sim(model = list(order = c(1, 1, 1), ar = 0.8, ma = 0.3), n = 200)
y <- arima.sim(model = list(order = c(1, 1, 1), ar = 0.8, ma = 0.3), n = 200)
plot(y)
set.seed(9)
x <- arima.sim(model = list(order = c(1, 1, 1),
ar = 0.6, ma = 0.2), n = 1000)
fit <- arima(x, order = c(1, 1, 1))
coefficients(fit)
fit
acf(resid(fit), main = "")
acf(resid(fit), main = "")
title(main = "Autocorrelaciones para los Residuales del Ajuste")
pred <- predict(fit, n.ahead = 3)
pred
pred$pred
pred
class(pred)
library(shiny); runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros8.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros8.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros8.R')
shinyApp(ui = ui, server = server)
shinyApp(ui = ui, server = server)
# Ejecutar la aplicación Shiny
shinyApp(ui = ui, server = server)
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros8.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros9.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros9.R')
library(shiny)
library(ggplot2)
library(dplyr)
library(DT)
carros <- read.csv("D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/carros.csv")
str(carros)
lm_model <- lm(vendido ~ edad_del_modelo + km_por_anio, data = carros)
str(lm_model)
# Cargar paquetes necesarios
library(shiny)
library(ggplot2)
library(dplyr)
library(DT)
# Cargar datos
carros <- read.csv("D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/carros.csv")
str(carros)
# Aplicar modelo de regresión lineal
lm_model <- lm(vendido ~ precio + km_por_anio, data = carros)
str(lm_model)
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros10.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros10.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros10.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros10.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros10.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros10.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros7.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros7.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros10.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros10.R')
carros <- read.csv("D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/carros.csv")
head(carros)
summary(carros)
par(mfrow = c(2, 2))
hist(carros$precio, main = "Distribución del precio", xlab = "Precio")
hist(carros$edad_del_modelo, main = "Distribución de la edad del modelo", xlab = "Edad del modelo")
hist(carros$km_por_anio, main = "Distribución de los kilómetros por año", xlab = "Kilómetros por año")
set.seed(123)  # Para reproducibilidad
train_index <- sample(1:nrow(carros), 0.8 * nrow(carros))
train_data <- carros[train_index, ]
test_data <- carros[-train_index, ]
# Modelo de regresión lineal
lm_model <- lm(precio ~ edad_del_modelo + km_por_anio, data = train_data)
lm_pred <- predict(lm_model, newdata = test_data)
lm_mse <- mean((lm_pred - test_data$precio)^2)
cat("Regresión Lineal MSE:", lm_mse, "\n")
# Modelo de regresión polinómica de grado 2
poly_model <- lm(precio ~ poly(edad_del_modelo, 2) + poly(km_por_anio, 2), data = train_data)
poly_pred <- predict(poly_model, newdata = test_data)
poly_mse <- mean((poly_pred - test_data$precio)^2)
cat("Regresión Polinómica de Grado 2 MSE:", poly_mse, "\n")
# Modelo de árbol de decisión
tree_model <- rpart(precio ~ edad_del_modelo + km_por_anio, data = train_data)
tree_pred <- predict(tree_model, newdata = test_data)
tree_mse <- mean((tree_pred - test_data$precio)^2)
cat("Árbol de Decisión MSE:", tree_mse, "\n")
# Modelo de bosque aleatorio
library(randomForest)
rf_model <- randomForest(precio ~ edad_del_modelo + km_por_anio, data = train_data)
rf_pred <- predict(rf_model, newdata = test_data)
rf_mse <- mean((rf_pred - test_data$precio)^2)
cat("Bosque Aleatorio MSE:", rf_mse, "\n")
# Run the application
shinyApp(ui = ui, server = server)
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros12.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/carros13.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros12.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros14.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros15.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros15.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros16.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros16.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros16.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros17.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros17.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros17.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros17.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros17.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros17.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros18.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros18.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros18.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros18.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros18.R')
runApp('D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/appcarros18.R')
library(shiny); runApp('appcarros18.R')
runApp('appcarros18.R')
#Funciona OK
# Cargar paquetes necesarios
library(shiny)
library(ggplot2)
library(DT)
library(dplyr)
library(corrplot)
# Cargar datos
carros <- read.csv("D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/carros.csv")
# Ajustar modelo de regresión polinómica de grado 2
poly_model <- lm(precio ~ poly(edad_del_modelo, 2) + poly(km_por_anio, 2), data = carros)
# Función para predecir si se venderá el carro y el precio estimado
predict_car <- function(edad, km) {
prediction <- predict(poly_model, newdata = data.frame(edad_del_modelo = edad, km_por_anio = km))
return(prediction)
}
View(predict_car)
print(prediction)
print(predict_car)
#Funciona OK
# Cargar paquetes necesarios
library(shiny)
library(ggplot2)
library(DT)
library(dplyr)
library(corrplot)
# Cargar datos
carros <- read.csv("D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/carros.csv")
# Ajustar modelo de regresión polinómica de grado 2
poly_model <- lm(precio ~ poly(edad_del_modelo, 2) + poly(km_por_anio, 2), data = carros)
# Función para predecir si se venderá el carro y el precio estimado
predict_car <- function(edad, km) {
prediction <- predict(poly_model, newdata = data.frame(edad_del_modelo = edad, km_por_anio = km))
return(prediction)
}
print(predict_car)
print(predict_car(10,20000))
print(predict_car(10,200000))
print(predict_car(100,200000))
print(predict_car(100,20000))
print(predict_car(1000,20000))
print(predict_car(1,20000))
runApp('appcarros19.R')
runApp('appcarros19.R')
runApp('appcarros19.R')
runApp('appcarros19.R')
runApp('appcarros18.R')
runApp('appcarros19.R')
runApp('appcarros19.R')
runApp('appcarros18.R')
runApp('appcarros19.R')
# Resumen de las características numéricas
summary(carros)
#Análisis del conjunto de datos
# Cargar datos
carros <- read.csv("D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/carros.csv")
# Visualizar las primeras filas de los datos
head(carros)
# Resumen de las características numéricas
summary(carros)
# Histogramas de las variables numéricas
par(mfrow = c(2, 2))
hist(carros$precio, main = "Distribución del precio", xlab = "Precio")
hist(carros$edad_del_modelo, main = "Distribución de la edad del modelo", xlab = "Edad del modelo")
hist(carros$km_por_anio, main = "Distribución de los kilómetros por año", xlab = "Kilómetros por año")
"Este código ajusta 4 modelos diferentes (regresión lineal, regresión polinómica de grado 2,
árbol de decisión y bosque aleatorio) al conjunto de datos de entrenamiento y evalua su rendimiento
en el conjunto de prueba utilizando el error cuadrático medio (MSE)"
# Dividir los datos en conjunto de entrenamiento y prueba (80% train, 20% test)
set.seed(123)  # Para reproducibilidad
train_index <- sample(1:nrow(carros), 0.8 * nrow(carros))
train_data <- carros[train_index, ]
test_data <- carros[-train_index, ]
# Modelo de regresión lineal
lm_model <- lm(precio ~ edad_del_modelo + km_por_anio, data = train_data)
lm_pred <- predict(lm_model, newdata = test_data)
lm_mse <- mean((lm_pred - test_data$precio)^2)
cat("Regresión Lineal MSE:", lm_mse, "\n")
# Modelo de regresión polinómica de grado 2
poly_model <- lm(precio ~ poly(edad_del_modelo, 2) + poly(km_por_anio, 2), data = train_data)
poly_pred <- predict(poly_model, newdata = test_data)
poly_mse <- mean((poly_pred - test_data$precio)^2)
cat("Regresión Polinómica de Grado 2 MSE:", poly_mse, "\n")
# Modelo de árbol de decisión
tree_model <- rpart(precio ~ edad_del_modelo + km_por_anio, data = train_data)
carros <- read.csv("D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/carros.csv")
head(carros)
summary(carros)
par(mfrow = c(2, 2))
hist(carros$precio, main = "Distribución del precio", xlab = "Precio")
hist(carros$edad_del_modelo, main = "Distribución de la edad del modelo", xlab = "Edad del modelo")
hist(carros$km_por_anio, main = "Distribución de los kilómetros por año", xlab = "Kilómetros por año")
set.seed(123)  # Para reproducibilidad
train_index <- sample(1:nrow(carros), 0.8 * nrow(carros))
train_data <- carros[train_index, ]
test_data <- carros[-train_index, ]
lm_model <- lm(precio ~ edad_del_modelo + km_por_anio, data = train_data)
lm_pred <- predict(lm_model, newdata = test_data)
lm_mse <- mean((lm_pred - test_data$precio)^2)
cat("Regresión Lineal MSE:", lm_mse, "\n")
poly_model <- lm(precio ~ poly(edad_del_modelo, 2) + poly(km_por_anio, 2), data = train_data)
poly_pred <- predict(poly_model, newdata = test_data)
poly_mse <- mean((poly_pred - test_data$precio)^2)
cat("Regresión Polinómica de Grado 2 MSE:", poly_mse, "\n")
tree_model <- rpart(precio ~ edad_del_modelo + km_por_anio, data = train_data)
library(randomForest)
rf_model <- randomForest(precio ~ edad_del_modelo + km_por_anio, data = train_data)
rf_pred <- predict(rf_model, newdata = test_data)
rf_mse <- mean((rf_pred - test_data$precio)^2)
cat("Bosque Aleatorio MSE:", rf_mse, "\n")
tree_model <- rpart(precio ~ edad_del_modelo + km_por_anio, data = train_data)
library(rpart)
tree_model <- rpart(precio ~ edad_del_modelo + km_por_anio, data = train_data)
tree_pred <- predict(tree_model, newdata = test_data)
tree_mse <- mean((tree_pred - test_data$precio)^2)
cat("Árbol de Decisión MSE:", tree_mse, "\n")
#Análisis del conjunto de datos
# Cargar datos
carros <- read.csv("D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/carros.csv")
# Visualizar las primeras filas de los datos
head(carros)
# Resumen de las características numéricas
summary(carros)
# Histogramas de las variables numéricas
par(mfrow = c(2, 2))
hist(carros$precio, main = "Distribución del precio", xlab = "Precio")
hist(carros$edad_del_modelo, main = "Distribución de la edad del modelo", xlab = "Edad del modelo")
hist(carros$km_por_anio, main = "Distribución de los kilómetros por año", xlab = "Kilómetros por año")
"Este código ajusta 4 modelos diferentes (regresión lineal, regresión polinómica de grado 2,
árbol de decisión y bosque aleatorio) al conjunto de datos de entrenamiento y evalua su rendimiento
en el conjunto de prueba utilizando el error cuadrático medio (MSE)"
# Dividir los datos en conjunto de entrenamiento y prueba (80% train, 20% test)
set.seed(123)  # Para reproducibilidad
train_index <- sample(1:nrow(carros), 0.8 * nrow(carros))
train_data <- carros[train_index, ]
test_data <- carros[-train_index, ]
# Modelo de regresión lineal
lm_model <- lm(precio ~ edad_del_modelo + km_por_anio, data = train_data)
lm_pred <- predict(lm_model, newdata = test_data)
lm_mse <- mean((lm_pred - test_data$precio)^2)
cat("Regresión Lineal MSE:", lm_mse, "\n")
# Modelo de regresión polinómica de grado 2
poly_model <- lm(precio ~ poly(edad_del_modelo, 2) + poly(km_por_anio, 2), data = train_data)
poly_pred <- predict(poly_model, newdata = test_data)
poly_mse <- mean((poly_pred - test_data$precio)^2)
cat("Regresión Polinómica de Grado 2 MSE:", poly_mse, "\n")
# Modelo de árbol de decisión
library(rpart)
tree_model <- rpart(precio ~ edad_del_modelo + km_por_anio, data = train_data)
tree_pred <- predict(tree_model, newdata = test_data)
tree_mse <- mean((tree_pred - test_data$precio)^2)
cat("Árbol de Decisión MSE:", tree_mse, "\n")
# Modelo de bosque aleatorio
library(randomForest)
rf_model <- randomForest(precio ~ edad_del_modelo + km_por_anio, data = train_data)
rf_pred <- predict(rf_model, newdata = test_data)
rf_mse <- mean((rf_pred - test_data$precio)^2)
cat("Bosque Aleatorio MSE:", rf_mse, "\n")
runApp('appcarros19.R')
runApp('appcarros20.R')
runApp('appcarros20.R')
runApp('appcarros19.R')
runApp('appcarros20.R')
runApp('appcarros20.R')
runApp('appcarros20.R')
runApp('appcarros20.R')
runApp('appcarros20.R')
runApp('appcarros20.R')
runApp('appcarros20.R')
runApp('appcarros20.R')
runApp('appcarros20.R')
runApp('appcarros20.R')
runApp('appcarros20.R')
#Análisis del conjunto de datos
# Cargar datos
carros <- read.csv("D:/BajadoEnD/20231218Módulo05Estadística&ProgramaciónConR/carros/carros.csv")
# Visualizar las primeras filas de los datos
head(carros)
# Resumen de las características numéricas
summary(carros)
# Histogramas de las variables numéricas
par(mfrow = c(2, 2))
hist(carros$precio, main = "Distribución del precio", xlab = "Precio")
hist(carros$edad_del_modelo, main = "Distribución de la edad del modelo", xlab = "Edad del modelo")
hist(carros$km_por_anio, main = "Distribución de los kilómetros por año", xlab = "Kilómetros por año")
"Este código ajusta 4 modelos diferentes (regresión lineal, regresión polinómica de grado 2,
árbol de decisión y bosque aleatorio) al conjunto de datos de entrenamiento y evalua su rendimiento
en el conjunto de prueba utilizando el error cuadrático medio (MSE)"
# Dividir los datos en conjunto de entrenamiento y prueba (80% train, 20% test)
set.seed(123)  # Para reproducibilidad
train_index <- sample(1:nrow(carros), 0.8 * nrow(carros))
train_data <- carros[train_index, ]
test_data <- carros[-train_index, ]
# Modelo de regresión lineal
lm_model <- lm(precio ~ edad_del_modelo + km_por_anio, data = train_data)
lm_pred <- predict(lm_model, newdata = test_data)
lm_mse <- mean((lm_pred - test_data$precio)^2)
cat("Regresión Lineal MSE:", lm_mse, "\n")
# Modelo de regresión polinómica de grado 2
poly_model <- lm(precio ~ poly(edad_del_modelo, 2) + poly(km_por_anio, 2), data = train_data)
poly_pred <- predict(poly_model, newdata = test_data)
poly_mse <- mean((poly_pred - test_data$precio)^2)
cat("Regresión Polinómica de Grado 2 MSE:", poly_mse, "\n")
# Modelo de árbol de decisión
library(rpart)
tree_model <- rpart(precio ~ edad_del_modelo + km_por_anio, data = train_data)
tree_pred <- predict(tree_model, newdata = test_data)
tree_mse <- mean((tree_pred - test_data$precio)^2)
cat("Árbol de Decisión MSE:", tree_mse, "\n")
# Modelo de bosque aleatorio
library(randomForest)
rf_model <- randomForest(precio ~ edad_del_modelo + km_por_anio, data = train_data)
rf_pred <- predict(rf_model, newdata = test_data)
rf_mse <- mean((rf_pred - test_data$precio)^2)
cat("Bosque Aleatorio MSE:", rf_mse, "\n")
library(shiny); runApp('appcarros20.R')
runApp('appcarros20.R')
